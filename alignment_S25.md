---
layout: page
title: Alignment Reading Group
---
## Table of Contents

1. [Agenda for February 7, 2025](#agenda-for-february-7-2025-ai-agi-and-ai-safety)
2. [Agenda for February 14, 2025](#agenda-for-february-14-2025-the-alignment-problem)


### Agenda for February 14, 2025: The Alignment Problem 

#### 1. Preliminaries (5 minutes)
* Let's do a quick round of introductions
* Reminder on discussion guidelines:
    * No need to close your laptop once you're done reading
    * However, please do close your laptop once the discussion starts

#### 2. Forecasting the Future Exercise (15 minutes)

#### 3. Core Content and Discussions

TBD

#### 4. Exit form

---

### Agenda for February 7, 2025: AI, AGI, and AI Safety

#### 1. Welcome and Introduction (5 minutes)
1. Introductions from Lawrence and Ida
   * Our backgrounds and motivation in AI safety
2. Discussion Guidelines
   * State your name before speaking (no formal introductions)
   * Active participation encouraged
   * Questions welcome - we're here to learn together
   * Laptops closed during discussion (exceptions for note-taking/quick searches)

#### 2. Program Structure (5 minutes)
* 8-week program (excluding finals week)
* No required preparation outside the 2-hour sessions
* Weekly Topics:
  * Week 1: What is AI, AI safety, and alignment?
  * Week 2: Alignment
  * Week 3: RLHF and other approaches to alignment
  * Week 4: Scalable oversight
  * Week 5: Robustness, unlearning
  * Week 6: Mechanistic interpretability
  * Week 7: Technical governance
  * Week 8: AI control
* Food provided at future meetings
* Guest facilitators include PhD students like Ida and Andy Zou
* Will be roughly based on [AISF](https://course.aisafetyfundamentals.com/alignment)

#### 3. Expectations Discussion (5 minutes)
* Group discussion of participant expectations and goals

#### 4. Initial Survey (5 minutes)
* Complete brief [introductory form](https://docs.google.com/forms/d/e/1FAIpQLSeTaOr4pMsmTWqIv2rIjoZ_Jw5WCMp8HmSNvEEUqqwyILkP5Q/viewform?usp=dialog)

#### 5. Core Content and Discussions
**5.1 Introduction to AI (25 minutes)**
* What can AI do now? What can't it do? (5 minutes)
* Reading and Discussion (10 minutes)
  * [AI and its impacts](https://aisafetyfundamentals.com/blog/ai-and-its-impacts/) 
  * [Why people are building AI](https://aisafetyfundamentals.com/blog/why-are-people-building-ai-systems/) 
* Group Discussion (10 minutes)
    * What is intelligence? What is artificial intelligence?

**5.2 What is Artificial General Intelligence (and how it might go wrong)? (40 minutes)**
* [What is AGI?](https://www.lesswrong.com/w/artificial-general-intelligence-agi) (5 minutes)
* [Paperclip maximizer](https://www.lesswrong.com/w/squiggle-maximizer-formerly-paperclip-maximizer) (5 minutes)
* [Instrumental Convergence](https://www.lesswrong.com/w/instrumental-convergence) (5 minutes)
* [Faulty systems in the wild](https://openai.com/index/faulty-reward-functions/)... watch the video! (5 minutes)

**5.3 Intelligence and Goals (20 minutes)**
* [Orthogonality thesis](https://www.lesswrong.com/w/orthogonality-thesis)
    * [Scott Aaronson on against orthogonality thesis](https://scottaaronson.blog/?p=7064)
* What do you think? (15 minutes)
    * Split in half and debate the orthogonality thesis

If time permits:
**5.4 More on Catastrophic AI Risks**
* Reading: [80,000 Hours - AI Problem Profile](https://80000hours.org/problem-profiles/artificial-intelligence/) (20 minutes)
* Partner Discussion: Timeline Perspectives (20 minutes)
  * What is a timeline?
  * What's your perspective on AI development timelines?
* Reading: [An Overview of Catastrophic AI Risks](https://arxiv.org/pdf/2306.12001) (5 minutes)
  * Focus: Section 3 - AI Race
* Summarize one risk in the readings (5 minutes)
* Further Discussion 
  * Key Questions:
    * Multipolar vs. unipolar development scenarios
    * Private vs. nationalized AI development
    * Open source vs. closed source approaches

Things that came up in discussion:
* [Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
* [Scaling Laws](https://arxiv.org/pdf/2001.08361)



