---
layout: page
title: Alignment Reading Group
---
## Table of Contents

1. [Agenda for February 7, 2025](#agenda-for-february-7-2025-ai-agi-and-ai-safety)
2. [Agenda for February 14, 2025](#agenda-for-february-14-2025-the-alignment-problem)


### Agenda for February 14, 2025: Alignment and RLHF

#### 1. Preliminaries (5 minutes)
* Let's do a quick round of introductions
* Please fill out the [introductory form](https://docs.google.com/forms/d/e/1FAIpQLSeTaOr4pMsmTWqIv2rIjoZ_Jw5WCMp8HmSNvEEUqqwyILkP5Q/viewform?usp=dialog)
* Reminder on discussion guidelines:
    * No need to close your laptop once you're done reading
    * However, please do close your laptop once the discussion starts

#### 2. Core Content and Discussions

**2.1 Review and Introduction to the Alignment Problem (20 minutes)**
* [What is AI alignment?](https://aisafetyfundamentals.com/blog/what-is-ai-alignment/) (15 minutes)

**2.2 Introduction to RLHF (30 minutes)**
<ul style="margin-top: 0px; padding-left: 20px;">
  <li><a href="https://huggingface.co/blog/rlhf">RLHF</a> (30 minutes)</li>
</ul>
  * This more technical article explains the motivations for a system like RLHF, and adds additional concrete details as to how the RLHF approach is applied to neural networks. While reading, consider which parts of the technical implementation correspond to the 'values coach' and 'coherence coach' from the previous video.

**2.3 Constitutional AI by Anthropic (60 minutes)**
<ul style="margin-top: 0px; padding-left: 20px;">
  <li><a href="https://arxiv.org/pdf/2212.08073">Constitutional AI</a> (60 minutes)</li>
</ul>
  * This paper explains Anthropicâ€™s constitutional AI approach, which is largely an extension on RLHF but with AIs replacing human demonstrators and human evaluators.

**2.4 Deliberative Alignment by OpenAI (30 minutes)**
* [Deliberative Alignment](https://arxiv.org/pdf/2412.16339) (30 minutes)
  * "We introduce Deliberative Alignment, a new paradigm that directly teaches the model safety specifications and trains it to explicitly recall and accurately reason over the specifications before answering."

**2.4 Open Problems in RLHF (20 minutes)**
* [Open Problems in RLHF](https://arxiv.org/pdf/2307.15217) (20 minutes)
  * This paper compiles a number of open problems in improving RLHF techniques.

---

### Agenda for February 7, 2025: AI, AGI, AI Safety

#### 1. Welcome and Introduction (5 minutes)
1. Introductions from Lawrence and Ida
   * Our backgrounds and motivation in AI safety
2. Discussion Guidelines
   * State your name before speaking (no formal introductions)
   * Active participation encouraged
   * Questions welcome - we're here to learn together
   * Laptops closed during discussion (exceptions for note-taking/quick searches)

#### 2. Program Structure (5 minutes)
* 8-week program (excluding finals week)
* No required preparation outside the 2-hour sessions
* Weekly Topics:
  * Week 1: What is AI, AI safety, and alignment?
  * Week 2: Alignment
  * Week 3: RLHF and other approaches to alignment
  * Week 4: Scalable oversight
  * Week 5: Robustness, unlearning
  * Week 6: Mechanistic interpretability
  * Week 7: Technical governance
  * Week 8: AI control
* Food provided at future meetings
* Guest facilitators include PhD students like Ida and Andy Zou
* Will be roughly based on [AISF](https://course.aisafetyfundamentals.com/alignment)

#### 3. Expectations Discussion (5 minutes)
* Group discussion of participant expectations and goals

#### 4. Initial Survey (5 minutes)
* Complete brief [introductory form](https://docs.google.com/forms/d/e/1FAIpQLSeTaOr4pMsmTWqIv2rIjoZ_Jw5WCMp8HmSNvEEUqqwyILkP5Q/viewform?usp=dialog)

#### 5. Core Content and Discussions
##### 5.1 Introduction to AI (30 minutes)**
* What can AI do now? What can't it do? (5 minutes)
* Reading and Discussion (10 minutes)
  * [AI and its impacts](https://aisafetyfundamentals.com/blog/ai-and-its-impacts/) 
  * [Why people are building AI](https://aisafetyfundamentals.com/blog/why-are-people-building-ai-systems/) 
  * [What is AGI?](https://www.lesswrong.com/w/artificial-general-intelligence-agi) (5 minutes)
* Group Discussion (10 minutes)
    * What is intelligence? What is artificial intelligence?

##### 5.2 Intelligence and Goals (70 minutes)**
* [The Superintelligent Will](https://nickbostrom.com/superintelligentwill.pdf) (30 minutes)
* [Faulty systems in the wild](https://openai.com/index/faulty-reward-functions/)... watch the video! (5 minutes)
* What do you think? Debate and discuss!
* Further readings:
  * [Scott Aaronson on against orthogonality thesis](https://scottaaronson.blog/?p=7064)

If time permits:

##### 5.3 More on Catastrophic AI Risks**
* Reading: [80,000 Hours - AI Problem Profile](https://80000hours.org/problem-profiles/artificial-intelligence/) (20 minutes)
* Partner Discussion: Timeline Perspectives (20 minutes)
  * What is a timeline?
  * What's your perspective on AI development timelines?
* Reading: [An Overview of Catastrophic AI Risks](https://arxiv.org/pdf/2306.12001) (5 minutes)
  * Focus: Section 3 - AI Race
* Summarize one risk in the readings (5 minutes)
* Further Discussion 
  * Key Questions:
    * Multipolar vs. unipolar development scenarios
    * Private vs. nationalized AI development
    * Open source vs. closed source approaches

Things that came up in discussion:
* [Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
* [Scaling Laws](https://arxiv.org/pdf/2001.08361)



