---
layout: page
title: Alignment Reading Group
---
### Agenda for 02/07/2025

1. Introductions from Lawrence and Ida!
2. Some brief guidelines:
    * We won't be doing introductions. Instead, before you speak, state your name. 
    * Please participate!
    * Don't be afraid to ask questions! We're coming from varied backgrounds, so we'll try to make sure we're all on the same page.
    * Have your laptops closed during discussion 
        * Unless you really want to search something up or write something down.
3. How will these reading groups be structured?
    * You don't have to do anything outside these two hours unless you want to!
    * These reading groups will run for approximately 8 weeks (no meetings before finals!)
    * Tentative schedule:
        * *Week 1*: What is AI, AI safety, and alignment?
        * *Week 2*: Alignment
        * *Week 3*: RLHF and other approaches to alignment
        * *Week 4*: Scalable oversight
        * *Week 5*: Robustness, unlearning
        * *Week 6*: Mechanistic interpretability
        * *Week 7*: Technical governance
        * *Week 8*: AI control
    * There should be food in the coming meetings!
4. Now that I've discussed my expectations, what are your expectations? 

---

5. To begin with, please fill out this [form](https://docs.google.com/forms/d/e/1FAIpQLSeTaOr4pMsmTWqIv2rIjoZ_Jw5WCMp8HmSNvEEUqqwyILkP5Q/viewform?usp=dialog).
6. [First reading]()
5. Little discussion about timelines and accelerating progress, small reading
6. Discussion topics:
    1. What is your timeline?
    2. Open source of close source?
    3. Multipolar or unipolar?


###








