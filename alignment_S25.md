---
layout: page
---

## Alignment Reading Group

### Agenda 02/07/2025

1. Introductions from Lawrence and Ida!
2. Some brief guidelines:
    * No introductions! Instead, before you speak, state your name. 
    * Participate!
    * Don't be afraid to ask questions! We're coming from varied backgrounds, so we'll try to make sure we're all on the same page.
    * Have your laptops closed during discussion (unless you really want to search something up or write something down).
3. How will these reading groups be structured?
    * There is no time commitment outside of these meetings!
    * These reading groups will run for approximately 8 weeks (no meetings before finals!)
    * Tentative schedule:
        * *Week 1*: What is AI, AI safety, and alignment?
        * *Week 2*: Alignment
        * *Week 3*: RLHF and other approaches
        * *Week 4*: Scalable oversight
        * *Week 5*: Robustness, unlearning
        * *Week 6*: Mechanistic interpretability
        * *Week 7*: Technical governance
        * *Week 8*: AI control
    * There should be food in the coming meetings!
4. Now that I've discussed my expectations, what are your expectations? 

#### 
5. To begin with, please fill out this [form](https://docs.google.com/forms/d/e/1FAIpQLSeTaOr4pMsmTWqIv2rIjoZ_Jw5WCMp8HmSNvEEUqqwyILkP5Q/viewform?usp=dialog).
5. Little discussion about timelines and accelerating progress, small reading
6. Discussion topics:
    1. What is your timeline?
    2. Open source of close source?
    3. Multipolar or unipolar?


###








