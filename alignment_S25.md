---
layout: page
title: Alignment Reading Group
---

### Agenda for February 7, 2025

#### 1. Welcome and Introduction (10 minutes)
1. Introductions from Lawrence and Ida
   * Our backgrounds and motivation in AI safety
2. Discussion Guidelines
   * State your name before speaking (no formal introductions)
   * Active participation encouraged
   * Questions welcome - we're here to learn together
   * Laptops closed during discussion (exceptions for note-taking/quick searches)

#### 2. Program Structure
* 8-week program (excluding finals week)
* No required preparation outside the 2-hour sessions
* Weekly Topics:
  * Week 1: What is AI, AI safety, and alignment?
  * Week 2: Alignment
  * Week 3: RLHF and other approaches to alignment
  * Week 4: Scalable oversight
  * Week 5: Robustness, unlearning
  * Week 6: Mechanistic interpretability
  * Week 7: Technical governance
  * Week 8: AI control
* Refreshments provided at future meetings
* Guest facilitators include PhD students like Ida and Andy Zou

#### 3. Expectations Discussion (5 minutes)
* Group discussion of participant expectations and goals

#### 4. Initial Survey (5 minutes)
* Complete brief [introductory form](https://docs.google.com/forms/d/e/1FAIpQLSeTaOr4pMsmTWqIv2rIjoZ_Jw5WCMp8HmSNvEEUqqwyILkP5Q/viewform?usp=dialog)

#### 5. Core Content and Discussions

**Introduction to AI (20 minutes)**
* What can AI do now? What can't it do?
* Reading and Discussion (10 minutes)
  * [AI and its impacts](https://aisafetyfundamentals.com/blog/ai-and-its-impacts/) (5 minutes)
  * [Why people are building AI](https://aisafetyfundamentals.com/blog/why-are-people-building-ai-systems/) (5 minutes)
* Group Discussion (10 minutes)
    * What is intelligence? What is artificial intelligence?

**What is Artificial General Intelligence (and how it might go wrong)? (20 minutes)**
* [What is AGI?](https://www.lesswrong.com/w/artificial-general-intelligence-agi)
* [Paperclip maximizer](https://www.lesswrong.com/w/squiggle-maximizer-formerly-paperclip-maximizer)
* [Faulty systems in the wild](https://openai.com/index/faulty-reward-functions/)
* What do you think?

**AI Futures (40 minutes)**
* Reading: [80,000 Hours - AI Problem Profile](https://80000hours.org/problem-profiles/artificial-intelligence/) (20 minutes)
* Partner Discussion: Timeline Perspectives (20 minutes)
  * What is a timeline?
  * What's your perspective on AI development timelines?

**Catastrophic AI Risks (45 minutes)**
* Reading: [An Overview of Catastrophic AI Risks](https://arxiv.org/pdf/2306.12001) (15 minutes)
  * Focus: Section 3 - AI Race
* Group Discussion (30 minutes)
  * Key Questions:
    * Multipolar vs. unipolar development scenarios
    * Private vs. nationalized AI development
    * Open source vs. closed source approaches