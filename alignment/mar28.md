---
layout: narrow
title: "Alignment Reading Group: March 28, 2025"
---
# Mechanistic Interpretability

> Mechanistic interpretability seeks to reverse engineer neural networks, similar to how one might reverse engineer a compiled binary computer program. After all, neural network parameters are in some sense a binary computer program which runs on one of the exotic virtual machines we call a neural network architecture.

Where does it fit into the broader picture of alignment?

<img src="/alignment/applications.png" alt="applications of mech interp" width="400" class="center"/>

## 1. Core Content and Discussions

#### 1.1 [Introduction to Mechanistic Interpretability](https://aisafetyfundamentals.com/blog/introduction-to-mechanistic-interpretability/) (15 minutes)

#### 1.2 [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/) (30 minutes)

#### 1.3 [Let's Try To Understand AI Monosemanticity](https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand) (25 minutes)
* Check out [Toy Model of Superposition](https://transformer-circuits.pub/2022/toy_model/index.html)
* Check out [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features/index.html) 

#### 1.4 (Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet) (10 minutes)
* Scaling Laws section [here](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html#scaling-scaling-laws)
* Examples of Feature Interpretability [here](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html#assessing-interp)
* [Feature Visualization](https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html#feature-442)

#### 1.5 [Insights on Crosscoder Model Diffing](https://transformer-circuits.pub/2025/crosscoder-diffing-update/index.html)  (if time permits)

#### 1.6 [Theories of Impact for Interpretability](https://www.alignmentforum.org/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability)

## 2. Further Reading

#### 2.1 [GDM Depriortizing SAE Research](https://www.lesswrong.com/posts/C5KAZQib3bzzpeyrg/full-post-progress-update-1-from-the-gdm-mech-interp-team)

#### 2.2 [Open Problems in Mechanistic Interpretability](https://arxiv.org/pdf/2501.16496)

