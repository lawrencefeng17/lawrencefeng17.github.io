---
layout: post
title: Solving Jigsaw Puzzles using Reinforcement Learning
subtitle: 11-785 Final Project
thumbnail-img: "puzzle.png"
gh-repo: james-ngai/11-785-Project
tags: [Projects]
author: Lawrence Feng
---

## Inspiration

This project began from a desire to meld reinforcement learning with image manipulation. Convolutional neural networks (CNN) can perform position-invariant classification (i.e. a CNN can identify a flower in an image no matter where the flower is in the image).

But what if we wanted to perform a different sort of *something*-invariant classification? For example, classification invariant under corruption, scrambling, etc. We want to be able to dynamically extract features from an image under variation so that we are still able to perform classification. This area of research is called dynamic feature selection or active feature acquisition.

## What we did

Unfortunately, due to limited experience with reinforcement learning and limited time, we settled for a simpler reinforcement learning problem that allowed us to learn RL and apply our familiarity with CNNs.

We trained a reinforcement learning agent to perform image reassembly on scrambled jigsaw puzzles of the MNIST dataset. 

We took MNIST images and created 3x3 jigsaw puzzles out of them. We framed this jigsaw game as a sequentially swapping game, where each move involved swapping one tile with another. We wanted the agent to place the puzzle pieces in their original places in the least number of moves.

## Architecture and Pipeline

AlphaZero's architecture inspired us. 

We trained a value network with a CNN backbone to take in a jigsaw puzzle at some point in the reassembly process and output a scalar from 0 to 1 labeling how close it was to being reassembled.

We trained a policy network with a CNN backbone to take in a jigsaw puzzle at some point in the reassembly process and output a set of action-probability pairs (action referring to a valid move/swap).

Then we performed Monte Carlo Tree Search with PUCT that combined the value network and the policy network to perform depth reduction and breadth reduction, respectively.

## Summary video of what we did!

[Project video](https://www.youtube.com/watch?v=DpJcMY3AIuo&ab_channel=LawrenceFeng)
